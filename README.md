# Adaptive Discriminative Region Discovery for Scene Recognition

By [Zhengyu Zhao](https://zhengyuzhao.github.io/).

Radboud University.

### Introduction

This repository contains the Python implementation of "Adi-Red" approach described in our paper:
**[From Volcano to Toyshop: Adaptive Discriminative Region Discovery for Scene Recognition](https://dl.acm.org/citation.cfm?id=3240698),**
Zhengyu Zhao and Martha Larson, ACMMM 2018.
<p align="center">
  <img src="https://github.com/ZhengyuZhao/Adaptive-Discriminative-Region-Discovery/blob/master/figures/diagram_textwidth.jpg" width='600'>
</p>


Adi-Red can derive discriminative information of a scene image directly from a CNN classifier, and achieved state-of-the-art scene recognition performance on [SUN397](https://groups.csail.mit.edu/vision/SUN/) in terms of Top-1 Acc, by adopting a multi-scale patch feature aggegation pipeline.

### Implementation

#### Overview

This code implements:
 1. Generating discriminative map (Dis-Map) for scene images
 2. Adptively selecting multi-scale discriminative patches
 3. Aggregating CNN features from both local and global scale to obtain the final image representation
 4. Evaluating the scene image recognition on SUN397 and Places
 
#### Prerequisites

In order to run the code, you need:

1. Python3 (tested with Python 3.7.2 on Ubuntu 16.04.6 LTS)
1. PyTorch deep learning framework (tested with version 1.0.1)
1. All the rest (data + networks) will be automatically downloaded with our scripts



### Citation

If you use this approach in your research, please cite:

	@article{Zhao2018,
		author = {Zhengyu Zhao and Martha Larson},
		title = {From Volcano to Toyshop: Adaptive Discriminative Region Discovery for Scene Recognition},
		Booktitle={ACM International Conference on Multimedia},
		Year={2018}
	}


### Results

1. We use the multi-scale deep features generated by our approach to train a linear SVM classifier with parameter C fixed for all the     implementations.
Top-1 accuracy on SUN397: 

	Networks|Baseline|Adi-Red
	:---:|:---:|:---:
	AlexNet|54.17%|61.01%
	ResNet-18|66.96%|70.58%
	ResNet-50|71.38%|73.59%
	
2. Visualization of discriminative patches (smallest-scale) discovered by Adi-Red on Places365-Standard validation set. Specially, some patches (from "airfield", "bathroom" and "Japanese garden") convey object-level information. Other patches (from "baseball field" and "campsite") capture contextual semantics, i.e., the interaction between object parts and their surroundings. In another case, non-objectness patterns are captured successfully for the scenes (such as "crosswalk" and "beach"), where finding nameable objects (for example, people and cars in the crosswalk scene) based on region proposals is redundant and might even introduce confusion instead of contributing to their discriminative properties.

![patches](https://github.com/ZhengyuZhao/Adaptive-Discriminative-Region-Discovery/blob/master/figures/discriminative_patches_final.jpg)

